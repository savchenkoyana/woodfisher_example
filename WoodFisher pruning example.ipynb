{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d7f72d-6a8d-4922-a8c9-9e659c9dc718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43788b65-e067-415f-91c6-94c10e86e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/savchenko/projects/mlperf-tiny/benchmark/training_torch/image_classification/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca2588-ccef-474e-bf6c-d4708778a5ff",
   "metadata": {},
   "source": [
    "## Generate synthetic data, train linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872b28a3-a483-49d9-9a63-00e13729986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=3, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=3, out_features=2, bias=False),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c525be-5c72-4655-963e-ea9d5992ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 1000\n",
    "batch_size = 10\n",
    "\n",
    "x = np.random.randn(dataset_size, 2)\n",
    "y1 = x[:, 0] * 5\n",
    "y2 = x[:, 0] * 3 - x[:, 1] * 2\n",
    "y = np.zeros_like(x)\n",
    "y[:, 0] = y1\n",
    "y[:, 1] = y2\n",
    "\n",
    "tensor_x = torch.Tensor(x) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(y)\n",
    "\n",
    "my_dataset = TensorDataset(tensor_x, tensor_y) # create your datset\n",
    "my_dataloader = DataLoader(my_dataset, batch_size=batch_size) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925cbb7d-1e93-4127-8d0f-1bc96e9aff05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 5e-3\n",
    "lr_decay = 0.99\n",
    "my_net.train()\n",
    "optim = torch.optim.SGD(my_net.parameters(), lr=lr)\n",
    "\n",
    "train_scheduler = LambdaLR(\n",
    "    optimizer=optim, lr_lambda=lambda epoch: lr_decay**epoch\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53d0059-9aa6-447d-a7e7-24913fb33940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== loss === 18.090970993041992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/savchenko/projects/mlperf-tiny/benchmark/training_torch/image_classification/venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== loss === 1.0944627523422241\n",
      "=== loss === 1.0761324167251587\n",
      "=== loss === 1.0718954801559448\n",
      "=== loss === 1.074318289756775\n",
      "=== loss === 1.0783538818359375\n",
      "=== loss === 1.0761851072311401\n",
      "=== loss === 1.0689371824264526\n",
      "=== loss === 1.0653672218322754\n",
      "=== loss === 1.063279151916504\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (net_inp, target) in enumerate(my_dataloader):\n",
    "        net_inp = net_inp.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        pred = my_net(net_inp)\n",
    "        loss = loss_fn(pred, target)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if epoch % 10 == 0 and i % 100 == 0:\n",
    "            print(f\"=== loss === {loss}\")\n",
    "\n",
    "    train_scheduler.step(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f7a41-b96b-40a6-aa60-f720254e968d",
   "metadata": {},
   "source": [
    "## Expand model (create excess weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e10175-a872-425f-a85a-2d10a39fcc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=4, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=4, out_features=2, bias=False),\n",
    ")\n",
    "\n",
    "nn.init.zeros_(expanded_model[0].weight);\n",
    "nn.init.zeros_(expanded_model[2].weight);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53bebc20-c1b6-4f2a-a832-218ac55775e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh0 = my_net[0].weight.shape\n",
    "sh2 = my_net[2].weight.shape\n",
    "\n",
    "expanded_model[0].weight.data[:sh0[0], :sh0[1]] = my_net[0].weight.data\n",
    "expanded_model[2].weight.data[:sh2[0], :sh2[1]] = my_net[2].weight.data\n",
    "\n",
    "expanded_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e862b3-0a63-4e08-adef-da6323933fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.4329, -0.4615],\n",
       "        [-0.6964, -1.3951],\n",
       "        [-2.4095,  0.5311],\n",
       "        [ 0.0000,  0.0000]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f320111-f785-4d82-b74d-e20aa14c2dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.4329, -0.4615],\n",
       "        [-0.6964, -1.3951],\n",
       "        [-2.4095,  0.5311]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf2e5ba-d88a-4ac0-9420-55da791cb527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Check that outputs are the same\n",
    "\n",
    "inp = torch.rand((10, 2)).to(device)\n",
    "print(expanded_model(inp) - my_net(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e66ef-4691-4daa-9878-c70fdaad7a2b",
   "metadata": {},
   "source": [
    "## Pruning\n",
    "\n",
    "Pruning criterion taken from https://arxiv.org/pdf/2004.14340.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8d2693d-cffb-4e7f-847e-580bec7a6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FisherMatrix:\n",
    "    \"\"\"Based on article: https://arxiv.org/pdf/2004.14340.pdf\"\"\"\n",
    "    def __init__(self, device=None):\n",
    "        self._n_batches_tracked = 0\n",
    "        self._fisher_matrix = None\n",
    "        if device:\n",
    "            self._device = device\n",
    "        else:\n",
    "            self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def update(self, grads: torch.Tensor, batch_size: int):\n",
    "        grads_T = grads.reshape((*grads.shape, 1))\n",
    "\n",
    "        if self._fisher_matrix is None:\n",
    "            self._fisher_matrix = 0\n",
    "\n",
    "        self._fisher_matrix += grads_T * grads\n",
    "        self._n_batches_tracked += 1\n",
    "\n",
    "    def get(self):\n",
    "        if self._fisher_matrix is not None:\n",
    "            return self._fisher_matrix / self._n_batches_tracked\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a48d05-d8e2-4894-a83e-3a5d3a5d0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = FisherMatrix(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec873e1d-d794-4bd0-b03f-86c8d7e6bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net_inp, target in my_dataloader:\n",
    "    optim.zero_grad()\n",
    "\n",
    "    net_inp = net_inp.to(device)\n",
    "    target = target.to(device)    \n",
    "\n",
    "    out = expanded_model(net_inp)\n",
    "    loss = loss_fn(out, target)\n",
    "    loss.backward()\n",
    "\n",
    "    fm.update(\n",
    "        grads=torch.flatten(expanded_model[0].weight.grad),\n",
    "        batch_size=my_dataloader.batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ec2159-20d8-490b-b8f0-db6f07b60a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_criterion(ind_x, ind_y, weights, hessian, grads):\n",
    "    try:\n",
    "        hessian_inv = torch.linalg.inv(hessian)\n",
    "    except:\n",
    "        hessian_inv = torch.linalg.inv(hessian + 1e-6 * torch.eye(hessian.shape[0]).to(hessian.device))\n",
    "\n",
    "    # print(hessian_inv)\n",
    "\n",
    "    w_q = weights[ind_y, ind_x]\n",
    "    h, w = weights.shape\n",
    "    idx = ind_x + ind_y * w\n",
    "    h_inv_qq = hessian_inv[idx, idx]\n",
    "\n",
    "    l1 = 0.5 * w_q**2 / h_inv_qq\n",
    "    l2 = 0.5 * (hessian_inv[idx, :] @ grads)**2 / h_inv_qq\n",
    "    l3 = -w_q * (hessian_inv[idx, :] @ grads) / h_inv_qq\n",
    "    l4 = -0.5 * grads.T @ hessian_inv @ grads\n",
    "    print(f\"l1={l1.item()}, l2={l2.item()}, l3={l3.item()}, l4={l4.item()}\")\n",
    "\n",
    "    return l1.item() + l2.item() + l3.item() + l4.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf33c943-0172-4139-9ffc-72517e0fd30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights on first linear layer: tensor([[ 2.4329, -0.4615],\n",
      "        [-0.6964, -1.3951],\n",
      "        [-2.4095,  0.5311],\n",
      "        [ 0.0000,  0.0000]], device='cuda:0')\n",
      "We want to prune weight at indices (3, 1) with value 0.0\n"
     ]
    }
   ],
   "source": [
    "ind_y = 3\n",
    "ind_x = 1\n",
    "\n",
    "print(f\"Weights on first linear layer: {expanded_model[0].weight.data}\")\n",
    "print(f\"We want to prune weight at indices {ind_y, ind_x} with value {expanded_model[0].weight[ind_y, ind_x]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc57a8a7-3917-4a4c-ab48-ade965b6e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1=0.0, l2=0.0, l3=-0.0, l4=-3.492868185043335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4097893/818891512.py:17: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  l4 = -0.5 * grads.T @ hessian_inv @ grads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.492868185043335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruning_criterion(\n",
    "    ind_x=ind_x,\n",
    "    ind_y=ind_y,\n",
    "    weights=expanded_model[0].weight,\n",
    "    hessian=fm.get(),\n",
    "    grads=torch.flatten(expanded_model[0].weight.grad),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1d6e1-2a22-417d-8af0-b35f92bb67c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e342830-b79e-4346-9ed1-729fa3b970d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb67fc-8c5d-42a2-b96c-5f5a645da8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
